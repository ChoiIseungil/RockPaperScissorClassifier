from __future__ import print_function
import argparse
import torch
import torch.nn as nn
import torch.nn.functional as F

class Custom_Network(nn.Module):
	def __init__(self):
		#super() function makes class inheritance more manageable and extensible
		super(Custom_Network, self).__init__()
		self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)
		self.conv1 = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=5, stride=1)
		self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=4, stride=2, padding=1, padding_mode='zeros')
		self.conv3 = nn.Conv2d(in_channels=50, out_channels=100, kernel_size=2, stride=2)
		self.maxpool2 = nn.MaxPool2d(kernel_size=4, stride=1)
		self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=1)
		self.linear1 = nn.Linear(2500,1000)
		self.linear2 = nn.Linear(1000,500)
		self.linear3 = nn.Linear(500,200)
		self.linear4 = nn.Linear(200,30)
		self.linear5 = nn.Linear(30,3)
		# self.linear5 = nn.Linear(2500,100)
		# self.linear6 = nn.Linear(100,50)
		# self.linear7 = nn.Linear(50,3)

	def forward(self, x):
		# print(x.size())
		x = torch.sigmoid(self.conv1(x)) #3*64*64 -> 20*60*60
		# print(x.size())
		x = self.maxpool1(x) #20*60*60 -> 20*30*30
		# print(x.size())
		x = torch.sigmoid(self.conv2(x)) #20*30*30 -> 50*15*15
		# print(x.size())
		x = self.maxpool2(x) # 50*15*15 -> 50*12*12
		# print(x.size())
		x = torch.sigmoid(self.conv3(x)) #50*12*12 -> 100*6*6
		# print(x.size())
		x = self.maxpool3(x) #100*6*6 -> 100*5*5
		# print(x.size())
		x = torch.flatten(x,1)  #100*5*5 -> 2500
		# print(x.size())
		x = torch.relu(self.linear1(x)) #2500 -> 1000
		x = torch.relu(self.linear2(x)) #1000 -> 500
		x = torch.relu(self.linear3(x)) #500 -> 200
		x = torch.relu(self.linear4(x)) #200 -> 30
		x = torch.relu(self.linear5(x))	#30 -> 3
		# x = torch.relu(self.linear5(x))
		# x = torch.relu(self.linear6(x))
		# x = torch.relu(self.linear7(x))
		output = F.log_softmax(x, dim = 1)  #3 - >1
		return output